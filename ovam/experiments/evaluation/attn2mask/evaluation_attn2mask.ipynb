{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(annotation, mask):\n",
    "    \"\"\"Annotation: ground truth (512, 512), Mask: prediction (512, 512)\"\"\"\n",
    "\n",
    "    # Compute intersection\n",
    "    intersection = np.sum(np.logical_and(annotation, mask))\n",
    "\n",
    "    # Compute union\n",
    "    union = np.sum(np.logical_or(annotation, mask))\n",
    "\n",
    "    # Compute intersection over union\n",
    "    iou_score = intersection / union\n",
    "\n",
    "    return intersection, union, iou_score\n",
    "\n",
    "def interpolate(heatmap: np.ndarray, size=(512, 512), mode=\"bilinear\"):\n",
    "    \"\"\"Interpolate heatmap to match the size of the ground truth\"\"\"\n",
    "\n",
    "    # Convert to torch tensor\n",
    "    heatmap = torch.from_numpy(heatmap)\n",
    "    # Add batch and channel dimension\n",
    "    heatmap = heatmap.unsqueeze(0)\n",
    "    if len(heatmap.shape) == 3:\n",
    "        heatmap = heatmap.unsqueeze(0)\n",
    "    \n",
    "    # Interpolate\n",
    "    heatmap = torch.nn.functional.interpolate(heatmap, size=size, mode=mode)\n",
    "    # Convert back to numpy\n",
    "    heatmap = heatmap.squeeze().squeeze().numpy()\n",
    "    \n",
    "    return heatmap\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import denseCRF\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "def densecrf(I, P):\n",
    "    \"\"\"\n",
    "    input parameters:\n",
    "        I    : a numpy array of shape [H, W, C], where C should be 3.\n",
    "               type of I should be np.uint8, and the values are in [0, 255]\n",
    "        P    : a probability map of shape [H, W, L], where L is the number of classes\n",
    "               type of P should be np.float32\n",
    "        param: a tuple giving parameters of CRF (w1, alpha, beta, w2, gamma, it), where\n",
    "                w1    :   weight of bilateral term, e.g. 10.0\n",
    "                alpha :   spatial distance std, e.g., 80\n",
    "                beta  :   rgb value std, e.g., 15\n",
    "                w2    :   weight of spatial term, e.g., 3.0\n",
    "                gamma :   spatial distance std for spatial term, e.g., 3\n",
    "                it    :   iteration number, e.g., 5\n",
    "    output parameters:\n",
    "        out  : a numpy array of shape [H, W], where pixel values represent class indices. \n",
    "    \"\"\"\n",
    "    w1    = 10.0  # weight of bilateral term\n",
    "    alpha = 80    # spatial std\n",
    "    beta  = 13    # rgb  std\n",
    "    w2    = 3.0   # weight of spatial term\n",
    "    gamma = 3     # spatial std\n",
    "    it    = 5.0   # iteration\n",
    "    param = (w1, alpha, beta, w2, gamma, it)\n",
    "    out = denseCRF.densecrf(I, P, param) \n",
    "    return out   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attn2Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VOC-sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('voc_sim')\n",
    "annotations_folder = dataset_path / 'annotations'\n",
    "\n",
    "\n",
    "apply_crf = False\n",
    "beta = 0.2\n",
    "beta_optimized = -0.2\n",
    "\n",
    "# Iterate throuth annotations\n",
    "results = []\n",
    "for annotation_path in tqdm(list(annotations_folder.iterdir())):\n",
    "    example_result_dict = {}\n",
    "    model, classname, seed, _ = annotation_path.stem.split('_')\n",
    "    image_path = dataset_path / f\"images/{model}_{classname}_{seed}_image.png\"\n",
    "    heatmap_path = dataset_path / f\"voc_sim_fixed/{model}_{classname}_{seed}_heatmap.npy\"\n",
    "    heatmap_optimized_path = dataset_path / f\"voc_sim_fixed/{model}_{classname}_{seed}_heatmapopt.npy\"\n",
    "    \n",
    "    # Check all exists\n",
    "    assert annotation_path.exists(), f\"Annotation {annotation_path} does not exist\"\n",
    "    assert image_path.exists(), f\"Image {image_path} does not exist\"\n",
    "    assert heatmap_path.exists(), f\"Heatmap {heatmap_path} does not exist\"\n",
    "    assert heatmap_optimized_path.exists(), f\"Heatmap {heatmap_optimized_path} does not exist\"\n",
    "    \n",
    "    # Add paths to result dict\n",
    "    example_result_dict['classname'] = classname\n",
    "    example_result_dict['model'] = model\n",
    "    example_result_dict['seed'] = seed\n",
    "    example_result_dict['image_path'] = image_path.name\n",
    "    example_result_dict['annotation_path'] = annotation_path.name\n",
    "    example_result_dict['heatmap_path'] = heatmap_path.name\n",
    "    example_result_dict['heatmap_optimized_path'] = heatmap_optimized_path.name\n",
    "\n",
    "    # Load annotation. Convert in binary mask\n",
    "    annotation = np.array(Image.open(annotation_path))\n",
    "    image = np.array(Image.open(image_path))\n",
    "    assert annotation.shape == (512, 512, 3), f\"Annotation {annotation_path} has wrong shape {annotation.shape}\"\n",
    "    annotation = annotation.sum(axis=-1) != 0\n",
    "    assert annotation.shape == (512, 512), f\"Annotation aggregated {annotation_path} has wrong shape {annotation.shape}\"\n",
    "    \n",
    "    heatmap = np.load(heatmap_path)[0]\n",
    "    heatmap = heatmap[-2] # Channel for the selected class\n",
    "    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
    "    #heatmap = heatmap / heatmap.max()\n",
    "    a0 = 1 - heatmap - beta # Background channel\n",
    "    attentions = np.stack([a0, heatmap], axis=0)\n",
    "    attentions = interpolate(attentions, size=(512, 512), mode=\"bilinear\")\n",
    "    mask = attentions.argmax(axis=0)\n",
    "    if apply_crf:\n",
    "        mask = np.stack([1 - mask, mask], axis=-1).astype(np.float32)\n",
    "        mask = densecrf(image, mask)\n",
    "        assert mask.shape == (512, 512), f\"Mask {heatmap_path} has wrong shape {mask.shape}\"\n",
    "\n",
    "    \n",
    "    # fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    # ax1.imshow(image)\n",
    "    # ax2.imshow(attentions[0])\n",
    "    # ax3.imshow(attentions[1])\n",
    "    # ax4.imshow(mask)\n",
    "    # continue\n",
    "\n",
    "\n",
    "\n",
    "    i_normal, u_normal, iou_normal = compute_iou(annotation=annotation, mask=mask)\n",
    "    example_result_dict['iou_normal'] = iou_normal\n",
    "    example_result_dict['i_normal'] = i_normal\n",
    "    example_result_dict['u_normal'] = u_normal\n",
    "\n",
    "    # Load mask (optimized)\n",
    "    heatmap_optimized = np.load(heatmap_optimized_path)\n",
    "    heatmap_optimized = heatmap_optimized[0, 1] # We stored in 0 the background and in 1 the token related to the foreground object\n",
    "    heatmap_optimized = (heatmap_optimized - heatmap_optimized.min()) / (heatmap_optimized.max() - heatmap_optimized.min())\n",
    "    #heatmap_optimized = heatmap_optimized / heatmap_optimized.max()\n",
    "    #print(\"EL heatmap range\", heatmap_optimized.max(), heatmap_optimized.min())\n",
    "    \n",
    "    a0_optimized = 1 - heatmap_optimized - beta_optimized\n",
    "    #print(\"EL a0 range\", a0_optimized.max(), a0_optimized.min())\n",
    "    attentions_optimized = np.stack([a0_optimized, heatmap_optimized], axis=0)\n",
    "    attentions_optimized = interpolate(attentions_optimized, size=(512, 512), mode=\"bilinear\")\n",
    "    mask_optimized = attentions_optimized.argmax(axis=0)\n",
    "    if apply_crf:\n",
    "        mask_optimized = np.stack([1 - mask_optimized, mask_optimized], axis=-1).astype(np.float32)\n",
    "        mask_optimized = densecrf(image, mask_optimized)\n",
    "\n",
    "    assert mask_optimized.shape == (512, 512), f\"Mask {heatmap_optimized_path} has wrong shape {mask_optimized.shape}\"\n",
    "    \n",
    "    # fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    # ax1.imshow(image)\n",
    "    # ax2.imshow(attentions_optimized[0])\n",
    "    # ax3.imshow(attentions_optimized[1])\n",
    "    # ax4.imshow(mask_optimized)\n",
    "    # continue\n",
    "    \n",
    "\n",
    "    i_optimized, u_optimized, iou_optimized = compute_iou(annotation=annotation, mask=mask_optimized)\n",
    "    example_result_dict['iou_optimized'] = iou_optimized\n",
    "    example_result_dict['i_optimized'] = i_optimized\n",
    "    example_result_dict['u_optimized'] = u_optimized\n",
    "\n",
    "    results.append(example_result_dict)\n",
    "\n",
    "    \n",
    "# Aggregated by example\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results['experiment'] = \"voc-sim - daam\"\n",
    "df_results.to_csv(dataset_path / 'daam_voc_sim_results.csv', index=False)\n",
    "\n",
    "\n",
    "# Aggregated results by class\n",
    "df_classes = df_results.groupby(['classname', 'model']).aggregate({'i_normal': 'sum', 'u_normal': 'sum', 'i_optimized': 'sum', 'u_optimized': 'sum'}).reset_index()\n",
    "df_classes['iou_normal'] = df_classes['i_normal'] / df_classes['u_normal']\n",
    "df_classes['iou_optimized'] = df_classes['i_optimized'] / df_classes['u_optimized']\n",
    "df_classes['experiment'] = \"voc-sim - daam\"\n",
    "df_classes = df_classes.sort_values('classname').reset_index(drop=True)\n",
    "df_classes.to_csv(dataset_path / 'daam_voc_sim_class_results.csv', index=False)\n",
    "\n",
    "df_overall = df_classes.groupby('model').aggregate({'i_normal': 'sum', 'u_normal': 'sum', 'i_optimized': 'sum', 'u_optimized': 'sum',\n",
    "                                        'iou_normal': 'mean', 'iou_optimized': 'mean'}).reset_index()\n",
    "\n",
    "df_overall.rename(columns={'iou_normal': 'miou_normal', 'iou_optimized': 'miou_optimized'}, inplace=True)\n",
    "df_overall['iou_overall_normal'] = df_overall['i_normal'] / df_overall['u_normal']\n",
    "df_overall['iou_overall_optimized'] = df_overall['i_optimized'] / df_overall['u_optimized']\n",
    "df_overall['experiment'] = \"voc-sim - daam\"\n",
    "df_overall.to_csv(dataset_path / 'daam_voc_sim_overall_results.csv', index=False)\n",
    "\n",
    "df_overall_display = df_overall[[\"miou_normal\",\"iou_overall_normal\", \"miou_optimized\",  \"iou_overall_optimized\"]]\n",
    "df_overall_display = (100*df_overall_display).round(1)\n",
    "display(df_overall_display)\n",
    "\n",
    "assert dataset_path.name == 'voc_sim', f\"Dataset path {dataset_path} is not voc_sim\"\n",
    "df_classes_display = df_classes[['classname', 'iou_normal', 'iou_optimized']].copy()\n",
    "df_classes_display['iou_normal'] = (100*df_classes_display['iou_normal']).round(1)\n",
    "df_classes_display['iou_optimized'] = (100*df_classes_display['iou_optimized']).round(1)\n",
    "df_classes_display.T.to_excel(dataset_path / 'daam_voc_sim_class_results.xlsx', index=False)\n",
    "display(df_classes_display.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO-cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "dataset_path = Path('coco_cap')\n",
    "annotations_folder = dataset_path / 'annotations'\n",
    "df_coco_captions = pd.read_csv('../coco_captions_sampled.csv')\n",
    "\n",
    "apply_crf = True\n",
    "beta = 0.2\n",
    "beta_optimized = -0.2\n",
    "# Iterate throuth annotations\n",
    "results = []\n",
    "for annotation_path in tqdm(list(annotations_folder.iterdir())):\n",
    "    example_result_dict = {}\n",
    "    model, classname, caption, seed, _ = annotation_path.stem.split('_')\n",
    "    model = model.replace('-', '')\n",
    "    image_path = dataset_path / f\"images/{model}_{classname}_{caption}_{seed}_image.png\"\n",
    "    heatmap_path = dataset_path / f\"heatmaps/{model}_{classname}_{caption}_{seed}_heatmap.npy\"\n",
    "    heatmap_optimized_path = dataset_path / f\"heatmaps_optimized/{model}_{classname}_{caption}_{seed}_heatmapopt.npy\"\n",
    "\n",
    "    assert annotation_path.exists(), f\"Annotation {annotation_path} does not exist\"\n",
    "    assert image_path.exists(), f\"Image {image_path} does not exist\"\n",
    "    assert heatmap_path.exists(), f\"Mask {heatmap_path} does not exist\"\n",
    "    assert heatmap_optimized_path.exists(), f\"Mask {heatmap_optimized_path} does not exist\"\n",
    "    \n",
    "    # Add paths to result dict\n",
    "    example_result_dict['classname'] = classname\n",
    "    example_result_dict['model'] = model\n",
    "    example_result_dict['seed'] = seed\n",
    "    \n",
    "    example_result_dict['image_path'] = image_path.name\n",
    "    example_result_dict['annotation_path'] = annotation_path.name\n",
    "    example_result_dict['heatmap_path'] = heatmap_path.name\n",
    "    example_result_dict['heatmap_optimized_path'] = heatmap_optimized_path.name\n",
    "\n",
    "    # Get info of coco caption used using caption_id\n",
    "    caption_id = int(caption.replace('caption', ''))\n",
    "    row = df_coco_captions.query(\"caption_id==@caption_id\")\n",
    "    assert len(row) == 1, f\"Caption {caption_id} not found in df_coco_captions\"\n",
    "    row = row.iloc[0]\n",
    "    prompt = row['caption']\n",
    "    word_included = row['word_included']\n",
    "    coco_categories = row['categories']\n",
    "\n",
    "    # Add info to results\n",
    "    example_result_dict['coco_caption_id'] = caption_id\n",
    "    example_result_dict['prompt'] = prompt\n",
    "    example_result_dict['word_included'] = word_included\n",
    "    example_result_dict['coco_categories'] = coco_categories\n",
    "\n",
    "    # Load annotation. Convert in binary mask\n",
    "    annotation = np.array(Image.open(annotation_path))\n",
    "    \n",
    "    assert annotation.shape == (512, 512, 3), f\"Annotation {annotation_path} has wrong shape {annotation.shape}\"\n",
    "    annotation = annotation.sum(axis=-1) != 0\n",
    "    assert annotation.shape == (512, 512), f\"Annotation aggregated {annotation_path} has wrong shape {annotation.shape}\"\n",
    "    image = np.array(Image.open(image_path))\n",
    "    # Load heatmap\n",
    "    heatmap = np.load(heatmap_path)[0]\n",
    "    heatmap = heatmap[-2] # Channel for the selected class\n",
    "    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
    "    #heatmap = heatmap / heatmap.max()\n",
    "    a0 = 1 - heatmap - beta # Background channel\n",
    "    attentions = np.stack([a0, heatmap], axis=0)\n",
    "    attentions = interpolate(attentions, size=(512, 512), mode=\"bilinear\")\n",
    "    mask = attentions.argmax(axis=0)\n",
    "    if apply_crf:\n",
    "        mask = np.stack([1 - mask, mask], axis=-1).astype(np.float32)\n",
    "        mask = densecrf(image, mask)\n",
    "        assert mask.shape == (512, 512), f\"Mask {heatmap_path} has wrong shape {mask.shape}\"\n",
    "\n",
    "    # # Plot image, heatmap, a0, mask\n",
    "    # fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    # ax1.imshow(Image.open(image_path))\n",
    "    # ax1.set_title(\"Image\")\n",
    "    # ax2.imshow(attentions[1])\n",
    "    # ax2.set_title(\"Heatmap\")\n",
    "    # ax3.imshow(attentions[0])\n",
    "    # ax3.set_title(\"a0\")\n",
    "    # ax4.imshow(mask)\n",
    "    # ax4.set_title(\"Mask\")\n",
    "\n",
    "    assert mask.shape == (512, 512), f\"Mask {heatmap_path} has wrong shape {mask.shape}\"\n",
    "\n",
    "    i_normal, u_normal, iou_normal = compute_iou(annotation=annotation, mask=mask)\n",
    "    example_result_dict['iou_normal'] = iou_normal\n",
    "    example_result_dict['i_normal'] = i_normal\n",
    "    example_result_dict['u_normal'] = u_normal\n",
    "    \n",
    "\n",
    "    # Load mask (optimized)\n",
    "    heatmap_optimized = np.load(heatmap_optimized_path)\n",
    "    heatmap_optimized = heatmap_optimized[0, 1] # We stored in 0 the background and in 1 the token related to the foreground object\n",
    "    heatmap_optimized = (heatmap_optimized - heatmap_optimized.min()) / (heatmap_optimized.max() - heatmap_optimized.min())\n",
    "    #heatmap_optimized = heatmap_optimized / heatmap_optimized.max()\n",
    "    #print(\"EL heatmap range\", heatmap_optimized.max(), heatmap_optimized.min())\n",
    "    \n",
    "    a0_optimized = 1 - heatmap_optimized - beta_optimized\n",
    "    #print(\"EL a0 range\", a0_optimized.max(), a0_optimized.min())\n",
    "    attentions_optimized = np.stack([a0_optimized, heatmap_optimized], axis=0)\n",
    "    attentions_optimized = interpolate(attentions_optimized, size=(512, 512), mode=\"bilinear\")\n",
    "    mask_optimized = attentions_optimized.argmax(axis=0)\n",
    "    if apply_crf:\n",
    "        mask_optimized = np.stack([1 - mask_optimized, mask_optimized], axis=-1).astype(np.float32)\n",
    "        mask_optimized = densecrf(image, mask_optimized)\n",
    "\n",
    "    assert mask_optimized.shape == (512, 512), f\"Mask {heatmap_optimized_path} has wrong shape {mask_optimized.shape}\"\n",
    "\n",
    "    i_optimized, u_optimized, iou_optimized = compute_iou(annotation=annotation, mask=mask_optimized)\n",
    "\n",
    "    example_result_dict['iou_optimized'] = iou_optimized\n",
    "    example_result_dict['i_optimized'] = i_optimized\n",
    "    example_result_dict['u_optimized'] = u_optimized\n",
    "\n",
    "    \n",
    "    # # Plot image, heatmap, a0, mask\n",
    "    # fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    # ax1.imshow(Image.open(image_path))\n",
    "    # ax1.set_title(\"Image\")\n",
    "    # ax2.imshow(attentions_optimized[1])\n",
    "    # ax2.set_title(\"Heatmap\")\n",
    "    # ax3.imshow(attentions_optimized[0])\n",
    "    # ax3.set_title(\"a0\")\n",
    "    # ax4.imshow(mask_optimized)\n",
    "    # ax4.set_title(\"Mask\")\n",
    "\n",
    "    results.append(example_result_dict)    \n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results['experiment'] = \"coco-cap - daam\"\n",
    "df_results.to_csv(dataset_path / 'attn2mask_coco_captions_results.csv', index=False)\n",
    "\n",
    "# All results (included and not included)\n",
    "assert dataset_path.name == 'coco_cap', f\"Dataset path {dataset_path} is not coco_captions\"\n",
    "\n",
    "# Aggregated results by class\n",
    "df_classes = df_results.groupby(['classname', 'model']).aggregate({'i_normal': 'sum', 'u_normal': 'sum', 'i_optimized': 'sum', 'u_optimized': 'sum'}).reset_index()\n",
    "df_classes['iou_normal'] = df_classes['i_normal'] / df_classes['u_normal']\n",
    "df_classes['iou_optimized'] = df_classes['i_optimized'] / df_classes['u_optimized']\n",
    "df_classes['experiment'] = \"voc-sim - attn2mask\"\n",
    "df_classes = df_classes.sort_values('classname').reset_index(drop=True)\n",
    "df_classes.to_csv(dataset_path / 'daam-cap_class_results_all.csv', index=False)\n",
    "\n",
    "df_classes_display = df_classes[[\"classname\", 'iou_normal', 'iou_optimized']].copy()\n",
    "df_classes_display['iou_normal'] = (100*df_classes_display['iou_normal']).round(1)\n",
    "df_classes_display['iou_optimized'] = (100*df_classes_display['iou_optimized']).round(1)\n",
    "df_classes_display.T.to_excel(dataset_path / 'daam-cap_class_results_all.xlsx', index=False)\n",
    "\n",
    "display(df_classes_display.T)\n",
    "\n",
    "# Aggregate overall results\n",
    "df_overall = df_classes.groupby('model').aggregate({'i_normal': 'sum', 'u_normal': 'sum', 'i_optimized': 'sum', 'u_optimized': 'sum',\n",
    "                                    'iou_normal': 'mean', 'iou_optimized': 'mean'}).reset_index()\n",
    "\n",
    "df_overall.rename(columns={'iou_normal': 'miou_normal', 'iou_optimized': 'miou_optimized'}, inplace=True)\n",
    "df_overall['iou_overall_normal'] = df_overall['i_normal'] / df_overall['u_normal']\n",
    "df_overall['iou_overall_optimized'] = df_overall['i_optimized'] / df_overall['u_optimized']\n",
    "df_overall['experiment'] = \"coco-cap - grounded diffusion\"\n",
    "df_overall.to_csv(dataset_path / 'daam-cap_overall_results_all.csv', index=False)\n",
    "df_overall_display = df_overall[['iou_overall_normal', 'miou_normal', 'iou_overall_optimized', 'miou_optimized']].copy()\n",
    "df_overall_display = (100*df_overall_display).round(1)\n",
    "display(df_overall_display[[\"miou_normal\",\"iou_overall_normal\", \"miou_optimized\",  \"iou_overall_optimized\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert dataset_path.name == 'coco_cap', f\"Dataset path {dataset_path} is not coco_captions\"\n",
    "\n",
    "for included in [True, False]:\n",
    "    included_str = 'included' if included else 'non_included'\n",
    "    print(included_str)\n",
    "    # Aggregated results by class\n",
    "    df_classes = df_results.query(\"word_included==@included\").groupby(['classname', 'model']).aggregate({'i_normal': 'sum', 'u_normal': 'sum', 'i_optimized': 'sum', 'u_optimized': 'sum'}).reset_index()\n",
    "    df_classes['iou_normal'] = df_classes['i_normal'] / df_classes['u_normal']\n",
    "    df_classes['iou_optimized'] = df_classes['i_optimized'] / df_classes['u_optimized']\n",
    "    df_classes['experiment'] = \"voc-sim - grounded diffusion\"\n",
    "    df_classes = df_classes.sort_values('classname').reset_index(drop=True)\n",
    "    #df_classes.to_csv(dataset_path / 'grounded_diffusion_coco-cap_class_results_all.csv', index=False)\n",
    "\n",
    "    df_classes_display = df_classes[[\"classname\", 'iou_normal', 'iou_optimized']].copy()\n",
    "    df_classes_display['iou_normal'] = (100*df_classes_display['iou_normal']).round(1)\n",
    "    df_classes_display['iou_optimized'] = (100*df_classes_display['iou_optimized']).round(1)\n",
    "    df_classes_display.T.to_excel(dataset_path / f'daam_coco-cap_class_results_{included_str}.xlsx', index=False)\n",
    "\n",
    "    display(df_classes_display.T)\n",
    "\n",
    "    # Aggregate overall results\n",
    "    df_overall = df_classes.groupby('model').aggregate({'i_normal': 'sum', 'u_normal': 'sum', 'i_optimized': 'sum', 'u_optimized': 'sum',\n",
    "                                        'iou_normal': 'mean', 'iou_optimized': 'mean'}).reset_index()\n",
    "\n",
    "    df_overall.rename(columns={'iou_normal': 'miou_normal', 'iou_optimized': 'miou_optimized'}, inplace=True)\n",
    "    df_overall['iou_overall_normal'] = df_overall['i_normal'] / df_overall['u_normal']\n",
    "    df_overall['iou_overall_optimized'] = df_overall['i_optimized'] / df_overall['u_optimized']\n",
    "    df_overall['experiment'] = \"coco-cap - grounded diffusion\"\n",
    "    df_overall.to_csv(dataset_path / f'daam_coco-cap_overall_results_{included_str}.csv', index=False)\n",
    "\n",
    "    df_overall_display = df_overall[['miou_normal', 'iou_overall_normal',  'miou_optimized', 'iou_overall_optimized']].copy()\n",
    "    df_overall_display = (100*df_overall_display).round(1)\n",
    "    display(df_overall_display)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable_diffusion_21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
